[
  {
    "id": "forge",
    "api_key_vars": "FORGE_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://antinomy.ai/api/v1/chat/completions",
    "models": "https://antinomy.ai/api/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "ai_studio",
    "api_key_vars": "GEMINI_API_KEY",
    "response_type": "OpenAI",
    "url": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
    "models": "https://generativelanguage.googleapis.com/v1beta/openai/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "opencode_zen",
    "api_key_vars": "ZEN_API_KEY",
    "response_type": "OpenAI",
    "url": "https://opencode.ai/zen/v1/chat/completions",
    "models": "https://opencode.ai/zen/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "mimo",
    "api_key_vars": "MIMO_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.xiaomimimo.com/v1/chat/completions",
    "models": "https://api.xiaomimimo.com/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "deepseek",
    "api_key_vars": "DEEPSEEK_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.deepseek.com/chat/completions",
    "models": "https://api.deepseek.com/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "github_copilot",
    "api_key_vars": "GITHUB_COPILOT_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.githubcopilot.com/chat/completions",
    "models": "https://api.githubcopilot.com/models",
    "auth_methods": [
      {
        "oauth_device": {
          "auth_url": "https://github.com/login/device/code",
          "token_url": "https://github.com/login/oauth/access_token",
          "client_id": "Iv1.b507a08c87ecfe98",
          "scopes": [
            "read:user"
          ],
          "use_pkce": false,
          "token_refresh_url": "https://api.github.com/copilot_internal/v2/token",
          "custom_headers": {
            "User-Agent": "GitHubCopilotChat/0.26.7",
            "Accept": "application/json",
            "editor-version": "vscode/1.99.3",
            "editor-plugin-version": "copilot-chat/0.26.7"
          }
        }
      }
    ]
  },
  {
    "id": "open_router",
    "api_key_vars": "OPENROUTER_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://openrouter.ai/api/v1/chat/completions",
    "models": "https://openrouter.ai/api/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "requesty",
    "api_key_vars": "REQUESTY_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://router.requesty.ai/v1/chat/completions",
    "models": "https://router.requesty.ai/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "xai",
    "api_key_vars": "XAI_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.x.ai/v1/chat/completions",
    "models": "https://api.x.ai/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "openai",
    "api_key_vars": "OPENAI_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.openai.com/v1/chat/completions",
    "models": "https://api.openai.com/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "openai_compatible",
    "api_key_vars": "OPENAI_API_KEY",
    "url_param_vars": [
      "OPENAI_URL"
    ],
    "response_type": "OpenAI",
    "url": "{{OPENAI_URL}}/chat/completions",
    "models": "{{OPENAI_URL}}/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "anthropic",
    "api_key_vars": "ANTHROPIC_API_KEY",
    "url_param_vars": [],
    "response_type": "Anthropic",
    "url": "https://api.anthropic.com/v1/messages",
    "models": "https://api.anthropic.com/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "claude_code",
    "api_key_vars": "CLAUDE_API_KEY",
    "url_param_vars": [],
    "response_type": "Anthropic",
    "url": "https://api.anthropic.com/v1/messages",
    "models": "https://api.anthropic.com/v1/models",
    "auth_methods": [
      {
        "oauth_code": {
          "auth_url": "https://claude.ai/oauth/authorize",
          "token_url": "https://console.anthropic.com/v1/oauth/token",
          "client_id": "9d1c250a-e61b-44d9-88ed-5944d1962f5e",
          "scopes": [
            "org:create_api_key",
            "user:profile",
            "user:inference"
          ],
          "redirect_uri": "https://console.anthropic.com/oauth/code/callback",
          "use_pkce": true,
          "extra_auth_params": {
            "code": "true"
          }
        }
      }
    ]
  },
  {
    "id": "anthropic_compatible",
    "api_key_vars": "ANTHROPIC_API_KEY",
    "url_param_vars": [
      "ANTHROPIC_URL"
    ],
    "response_type": "Anthropic",
    "url": "{{ANTHROPIC_URL}}/messages",
    "models": "{{ANTHROPIC_URL}}/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "cerebras",
    "api_key_vars": "CEREBRAS_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.cerebras.ai/v1/chat/completions",
    "models": "https://api.cerebras.ai/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "zai",
    "api_key_vars": "ZAI_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.z.ai/api/paas/v4/chat/completions",
    "models": [
      {
        "id": "glm-4.7",
        "name": "GLM-4.7",
        "description": "Latest flagship model series, foundational models specifically designed for agent applications with 200K context window and 128K maximum output",
        "context_length": 200000,
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.6",
        "name": "GLM-4.6",
        "description": "Last flagship model series, foundational models specifically designed for agent applications with 200K context window and 128K maximum output",
        "context_length": 200000,
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5",
        "name": "GLM-4.5",
        "description": "Advanced model with 128K context window and 96K maximum output, supports chain of thought",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-air",
        "name": "GLM-4.5-air",
        "description": "Lightweight version of GLM-4.5 with 128K context window and optimized performance",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-x",
        "name": "GLM-4.5-x",
        "description": "Extended version of GLM-4.5 with 128K context window and enhanced capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-airx",
        "name": "GLM-4.5-airx",
        "description": "Optimized version of GLM-4.5 with 128K context window and balanced performance and capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-flash",
        "name": "GLM-4.5-flash",
        "description": "Fast inference model with 128K context window for quick responses",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4-32b-0414-128k",
        "name": "GLM-4-32B-0414-128K",
        "description": "32B parameter model with 128K context window and 16K maximum output",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      }
    ],
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "zai_coding",
    "api_key_vars": "ZAI_CODING_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.z.ai/api/coding/paas/v4/chat/completions",
    "models": [
      {
        "id": "glm-4.7",
        "name": "GLM-4.7",
        "description": "Latest flagship model series, foundational models specifically designed for agent applications with 200K context window and 128K maximum output",
        "context_length": 200000,
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.6",
        "name": "GLM-4.6",
        "description": "Last flagship model series, foundational models specifically designed for agent applications with 200K context window and 128K maximum output",
        "context_length": 200000,
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5",
        "name": "GLM-4.5",
        "description": "Advanced model with 128K context window and 96K maximum output, supports chain of thought",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-air",
        "name": "GLM-4.5-air",
        "description": "Lightweight version of GLM-4.5 with 128K context window and optimized performance",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-x",
        "name": "GLM-4.5-x",
        "description": "Extended version of GLM-4.5 with 128K context window and enhanced capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-airx",
        "name": "GLM-4.5-airx",
        "description": "Optimized version of GLM-4.5 with 128K context window and balanced performance and capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-flash",
        "name": "GLM-4.5-flash",
        "description": "Fast inference model with 128K context window for quick responses",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4-32b-0414-128k",
        "name": "GLM-4-32B-0414-128K",
        "description": "32B parameter model with 128K context window and 16K maximum output",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      }
    ],
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "big_model",
    "api_key_vars": "BIG_MODEL_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://open.bigmodel.cn/api/paas/v4/chat/completions",
    "models": "https://open.bigmodel.cn/api/paas/v4/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "vertex_ai",
    "api_key_vars": "VERTEX_AI_AUTH_TOKEN",
    "url_param_vars": [
      "PROJECT_ID",
      "LOCATION"
    ],
    "response_type": "OpenAI",
    "url": "{{#if (eq LOCATION \"global\")}}https://aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/chat/completions{{else}}https://{{LOCATION}}-aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/chat/completions{{/if}}",
    "models": "{{#if (eq LOCATION \"global\")}}https://aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/models{{else}}https://{{LOCATION}}-aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/models{{/if}}",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "azure",
    "api_key_vars": "AZURE_API_KEY",
    "url_param_vars": [
      "AZURE_RESOURCE_NAME",
      "AZURE_DEPLOYMENT_NAME",
      "AZURE_API_VERSION"
    ],
    "response_type": "OpenAI",
    "url": "https://{{AZURE_RESOURCE_NAME}}.openai.azure.com/openai/deployments/{{AZURE_DEPLOYMENT_NAME}}/chat/completions?api-version={{AZURE_API_VERSION}}",
    "models": "https://{{AZURE_RESOURCE_NAME}}.openai.azure.com/openai/models?api-version={{AZURE_API_VERSION}}",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "llama_cpp",
    "api_key_vars": "LLAMA_CPP_API_KEY",
    "url_param_vars": [
      "LLAMA_CPP_URL",
      "LLAMA_CPP_PORT"
    ],
    "response_type": "OpenAI",
    "url": "{{LLAMA_CPP_URL}}:{{LLAMA_CPP_PORT}}/v1/chat/completions",
    "models": "{{LLAMA_CPP_URL}}:{{LLAMA_CPP_PORT}}/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "vllm",
    "api_key_vars": "VLLM_API_KEY",
    "url_param_vars": [
      "VLLM_URL",
      "VLLM_PORT"
    ],
    "response_type": "OpenAI",
    "url": "{{VLLM_URL}}:{{VLLM_PORT}}/v1/chat/completions",
    "models": "{{VLLM_URL}}:{{VLLM_PORT}}/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "jan_ai",
    "api_key_vars": "JAN_AI_API_KEY",
    "url_param_vars": [
      "JAN_AI_URL",
      "JAN_AI_PORT"
    ],
    "response_type": "OpenAI",
    "url": "{{JAN_AI_URL}}:{{JAN_AI_PORT}}/v1/chat/completions",
    "models": "{{JAN_AI_URL}}:{{JAN_AI_PORT}}/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "ollama",
    "api_key_vars": "OLLAMA_API_KEY",
    "url_param_vars": [
      "OLLAMA_URL",
      "OLLAMA_PORT"
    ],
    "response_type": "OpenAI",
    "url": "{{OLLAMA_URL}}:{{OLLAMA_PORT}}/v1/chat/completions",
    "models": "{{OLLAMA_URL}}:{{OLLAMA_PORT}}/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "lm_studio",
    "api_key_vars": "LM_STUDIO_API_KEY",
    "url_param_vars": [
      "LM_STUDIO_URL",
      "LM_STUDIO_PORT"
    ],
    "response_type": "OpenAI",
    "url": "{{LM_STUDIO_URL}}:{{LM_STUDIO_PORT}}/v1/chat/completions",
    "models": "{{LM_STUDIO_URL}}:{{LM_STUDIO_PORT}}/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "paws_services",
    "provider_type": "context_engine",
    "url": "https://api.pawscode.dev/",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "io_intelligence",
    "api_key_vars": "IO_INTELLIGENCE_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.intelligence.io.solutions/api/v1/chat/completions",
    "models": "https://api.intelligence.io.solutions/api/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "bedrock",
    "api_key_vars": "AWS_ACCESS_KEY_ID",
    "url_param_vars": [
      "AWS_SECRET_ACCESS_KEY",
      "AWS_REGION"
    ],
    "response_type": "Bedrock",
    "url": "",
    "models": [
      {
        "id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
        "name": "Claude 3.5 Sonnet",
        "context_length": 200000,
        "cost": {
          "input": 3.0,
          "output": 15.0
        },
        "description": "Anthropic's most intelligent model",
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": false
      },
      {
        "id": "anthropic.claude-3-5-haiku-20241022-v1:0",
        "name": "Claude 3.5 Haiku",
        "context_length": 200000,
        "cost": {
          "input": 1.0,
          "output": 5.0
        },
        "description": "Anthropic's fastest model",
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": false
      },
      {
        "id": "anthropic.claude-3-opus-20240229-v1:0",
        "name": "Claude 3 Opus",
        "context_length": 200000,
        "cost": {
          "input": 15.0,
          "output": 75.0
        },
        "description": "Anthropic's most powerful model",
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": false
      },
      {
        "id": "anthropic.claude-3-sonnet-20240229-v1:0",
        "name": "Claude 3 Sonnet",
        "context_length": 200000,
        "cost": {
          "input": 3.0,
          "output": 15.0
        },
        "description": "Anthropic's balanced model",
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": false
      },
      {
        "id": "anthropic.claude-3-haiku-20240307-v1:0",
        "name": "Claude 3 Haiku",
        "context_length": 200000,
        "cost": {
          "input": 0.25,
          "output": 1.25
        },
        "description": "Anthropic's fastest model",
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": false
      },
      {
        "id": "meta.llama3-1-405b-instruct-v1:0",
        "name": "Llama 3.1 405B Instruct",
        "context_length": 128000,
        "cost": {
          "input": 5.32,
          "output": 16.0
        },
        "description": "Meta's most capable model",
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      },
      {
        "id": "meta.llama3-1-70b-instruct-v1:0",
        "name": "Llama 3.1 70B Instruct",
        "context_length": 128000,
        "cost": {
          "input": 2.66,
          "output": 3.5
        },
        "description": "Meta's balanced model",
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      },
      {
        "id": "meta.llama3-1-8b-instruct-v1:0",
        "name": "Llama 3.1 8B Instruct",
        "context_length": 128000,
        "cost": {
          "input": 0.3,
          "output": 0.6
        },
        "description": "Meta's fastest model",
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      },
      {
        "id": "amazon.titan-text-express-v1",
        "name": "Titan Text Express",
        "context_length": 8000,
        "cost": {
          "input": 0.0008,
          "output": 0.0016
        },
        "description": "Amazon's balanced model",
        "tools_supported": false,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      },
      {
        "id": "amazon.titan-text-lite-v1",
        "name": "Titan Text Lite",
        "context_length": 4000,
        "cost": {
          "input": 0.0003,
          "output": 0.0004
        },
        "description": "Amazon's fastest model",
        "tools_supported": false,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      },
      {
        "id": "mistral.mistral-large-2402-v1:0",
        "name": "Mistral Large",
        "context_length": 32000,
        "cost": {
          "input": 8.0,
          "output": 24.0
        },
        "description": "Mistral's most capable model",
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      },
      {
        "id": "mistral.mistral-small-2402-v1:0",
        "name": "Mistral Small",
        "context_length": 32000,
        "cost": {
          "input": 2.0,
          "output": 6.0
        },
        "description": "Mistral's balanced model",
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      },
      {
        "id": "cohere.command-r-plus-v1:0",
        "name": "Command R+",
        "context_length": 128000,
        "cost": {
          "input": 3.0,
          "output": 15.0
        },
        "description": "Cohere's most capable model",
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      },
      {
        "id": "cohere.command-r-v1:0",
        "name": "Command R",
        "context_length": 128000,
        "cost": {
          "input": 0.5,
          "output": 1.5
        },
        "description": "Cohere's balanced model",
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      }
    ],
    "auth_methods": [
      "api_key"
    ]
  }
]
